# MSc Final Project: LLM-Guided Multi-Agent Robot Navigation in CoppeliaSim

This repository contains the implementation of a multi-robot navigation system that integrates classical path planning (A\*), real-time obstacle avoidance using simulated LiDAR sensors, and goal assignment driven by a Large Language Model (LLM). The system is built using Python and CoppeliaSim, with asynchronous control logic for coordinating multiple robots in parallel.

## ğŸ” Overview

This project showcases:

* A\* path planning on a dynamic occupancy grid
* Real-time obstacle detection and avoidance using SICK S300 sensors
* Robot coordination through cooperative path negotiation
* Natural language-based goal assignment via GPT-4
* Modular design for scalability and extensibility

## ğŸ“ Directory Structure

MSc-FInal-Project/
â”œâ”€â”€ main.py                # Entry point for robot coordination and simulation
â”œâ”€â”€ a_star.py              # A* path planning algorithm implementation
â”œâ”€â”€ astart_env.py          # Environment wrapper for A* algorithm
â”œâ”€â”€ map_builder.py         # Occupancy grid construction from sensor data
â”œâ”€â”€ robot_controller.py    # Robot movement and axis alignment logic
â”œâ”€â”€ sensor_fetch.py        # Interfaces with SICK S300 sensor data
â”œâ”€â”€ path_executor.py       # Executes robot motion paths asynchronously
â”œâ”€â”€ robot_awareness.py     # Cooperative obstacle handling between robots
â”œâ”€â”€ check_nearest_robot.py # Dynamic path clearance for blocked robots
â””â”€â”€ README.md              # Project documentation

## âœ… Features

* Multi-robot navigation with independent goals
* Asynchronous movement execution using asyncio
* Real-time feedback control using simulated LiDAR sensors
* Deadlock resolution through path and position awareness
* Modular Python scripts for easy adaptation and debugging

## âš™ï¸ Requirements

* Python 3.9+
* CoppeliaSim (latest version with ZeroMQ Remote API)
* Python dependencies:

  ```bash
  pip install numpy zmq asyncio matplotlib
  ```

## ğŸš€ How to Run

1. Open the simulation scene in CoppeliaSim
2. Start the simulation engine
3. Run the main control script:

   ```bash
   python main.py
   ```

Robots will begin navigating to assigned goals with obstacle awareness and cooperative movement.

## ğŸ¤– Sensor Configuration

Each robot is equipped with 4 SICK S300 vision sensors:

* `S3001_sensor1`: Front
* `S3001_sensor2`: Right
* `S300_sensor1`: Back
* `S300_sensor2`: Left

These sensors enable 360Â° awareness for reactive path adjustment.

## ğŸ§  LLM Integration

The project includes the capability to interface with an LLM (such as GPT-4) for:

* Interpreting natural language goal input
* Assigning coordinates to robots dynamically
* Supporting human-in-the-loop robot control

## ğŸ“Œ Future Enhancements

* Add SLAM support for real-world deployment
* Integrate GUI for manual or voice-based goal input
* Replace A\* with learning-based or dynamic planners
* Evaluate performance across complex multi-agent scenarios

## ğŸ‘¤ Author

**Mohamad Dirani**
MSc Robotics and Artificial Intelligence
University of Hertfordshire
GitHub: [@mohamaddirani](https://github.com/mohamaddirani)

## ğŸ“„ License

This project is provided for academic purposes only. Contact the author for reuse or collaboration opportunities.
